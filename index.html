<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta property="og:title" content="LoVoRA: Text-guided and Mask-free Video Object Removal and Addition with Learnable Object-aware Localization"/>
  <meta property="og:url" content="https://cz-5f.github.io/LoVoRA.github.io" />

  <meta name="keywords" content="video diffusion models, video editing, object removal, object addition, mask-free video editing">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>LoVoRA: Text-guided and Mask-free Video Object Removal and Addition with Learnable Object-aware Localization</title>
  <link rel="icon" type="image/x-icon" href="static/images/icons8.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <style>
  /* 1. Smaller title font */
  h1.publication-title {
  font-size: 2.3rem !important; 
  }


  .dataset-table th, .dataset-table td {
  border: 1px solid #ccc;
  padding: 8px;
  }
  .dataset-table {
  border-collapse: collapse;
  margin: 0 auto;
  }
  </style>


</head>
<body>

  <!-- Hero / Title section -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-fluid">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              LoVoRA: Text-guided and Mask-free Video Object Removal and<br>Addition with Learnable Object-aware Localization
            </h1>

            <!-- Authors -->
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                Zhihan Xiao<sup>1</sup>,
              </span>
              <span class="author-block">
                Lin Liu<sup>2<sup>&#9993;†</sup></sup>,
              </span>
              <span class="author-block">
                Yixin Gao<sup>3</sup>,
              </span>
              <span class="author-block">
                Xiaopeng Zhang<sup>2</sup>,
              </span>
              <span class="author-block">
                Haoxuan Che<sup>2</sup>,
              </span>
              <span class="author-block">
                Songping Mai<sup>1<sup>&#9993;</sup></sup>,
              </span>
              <span class="author-block">
                Qi Tian<sup>2</sup>
              </span>
            </div>

            <!-- Affiliations -->
            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Tsinghua University,</span>
              <span class="author-block"><sup>2</sup>Huawei Inc.,</span>
              <span class="author-block"><sup>3</sup>University of Science and Technology of China</span>
              <span class="eql-cntrb">
                <small>
                  <br>
                  <sup>†</sup>Project Leader,
                  <sup>&#9993;</sup>Corresponding authors
                </small>
              </span>
            </div>

            <!-- Links: Code / Arxiv / etc. -->
            <div class="column has-text-centered">
              <div class="code-links">
                <!-- Code link -->
                <span class="link-block">
                  <a href="https://github.com/cz-5f/LoVoRA.github.io" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (Coming soon)</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2512.02933" target="_blank"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>

                <!-- HuggingFace Dataset (Added) -->
                <span class="link-block">
                <a href="https://huggingface.co/datasets/cz-5f/LoVoRA" target="_blank" class="external-link button is-normal is-rounded is-link">
                <span class="icon"><i class="fa fa-database"></i></span>
                <span>Dataset</span>
                </a>
                </span>

              </div>
            </div>

          </div> <!-- column -->
        </div> <!-- columns -->
      </div> <!-- container -->
    </div> <!-- hero-body -->
  </section>

  <!-- Abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Text-guided video editing, particularly for object removal and addition, remains a challenging task
              due to the need for precise spatial and temporal consistency. Existing methods often rely on auxiliary
              masks or reference images for editing guidance, which limits their scalability and generalization.
              To address these issues, we propose LoVoRA, a novel framework for mask-free video object removal and
              addition using an object-aware localization mechanism. Our approach utilizes a unique dataset construction
              pipeline that integrates image-to-video translation, optical-flow-based mask propagation, and video
              inpainting, enabling temporally consistent edits. The core innovation of LoVoRA is its learnable
              object-aware localization mechanism, which provides dense spatio-temporal supervision for both object
              insertion and removal tasks. By leveraging a Diffusion Mask Predictor, LoVoRA achieves end-to-end video
              editing without requiring external control signals during inference. Extensive experiments and human
              evaluation demonstrate the effectiveness and high-quality performance of LoVoRA.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

<!-- NEW SECTION: Dataset Section -->
<section class="section hero">
<div class="container is-max-desktop">
<h2 class="title is-3">LoVoRA Dataset</h2>


<!-- <p class="has-text-justified">
The LoVoRA dataset is constructed from image editing pairs and extended into video editing instructions using I2V translation, mask propagation, and video inpainting.
</p> -->


<h3 class="title is-5">Dataset Examples</h3>
<div class="columns is-centered">

  <style>
    .fixed-title {
      height: 48px;       
      display: flex;
      align-items: center; 
      justify-content: center; 
      text-align: center;
    }
  </style>

  <div class="column has-text-centered">
    <div class="fixed-title">
      <h3 class="title is-6">
        Erase a pair of floral gardening gloves lying open on the sunny rooftop garden table.
      </h3>
    </div>
    <video poster="" playsinline autoplay muted loop width="100%" src="static/videos/data_remove.mp4"></video>
  </div>

  <div class="column has-text-centered">
    <div class="fixed-title">
      <h3 class="title is-6">
        Place a teddy bear on the lower bunk.
      </h3>
    </div>
    <video poster="" playsinline autoplay muted loop width="100%" src="static/videos/data_add.mp4"></video>
  </div>

  <div class="column has-text-centered">
    <div class="fixed-title">
      <h3 class="title is-6">
        Replace the beanie with a classic cap.
      </h3>
    </div>
    <video poster="" playsinline autoplay muted loop width="100%" src="static/videos/data_change.mp4"></video>
  </div>

</div>



<h3 class="title is-5">Dataset Comparison</h3>

<p class="has-text-justified">
Our dataset emphasizes high-resolution, temporally consistent object manipulation with
optical flow guided mask propagation. We also report VLM evaluation results using MiniCPM-V2.6. PF denotes Prompt Following and
EQ denotes Edit Quality.
</p>

<style>
table.dataset-table {
width: 70%;
border-collapse: collapse;
font-size: 1rem;
margin-top: 1rem;
}
table.dataset-table th {
background: #f5f5f5;
padding: 10px;
text-align: center;
font-weight: 700; 
font-size: 1.1rem; 
border-bottom: 2px solid #ccc;
}
table.dataset-table td {
padding: 8px;
text-align: center;
border-bottom: 1px solid #e5e5e5;
}
table.dataset-table tr:nth-child(even) td {
background: #fafafa;
}
table.dataset-table tr:hover td {
background: #f0f8ff;
}
</style>

<table class="dataset-table">
<tr>
<th>Dataset</th><th>PF</th><th>EQ</th><th>Generation Basis</th>
</tr>


<tr><td>InsV2V</td><td>--</td><td>--</td><td>Modified Prompt-to-Prompt method</td></tr>
<tr><td>ICVE-SFT</td><td>--</td><td>--</td><td>Source object removal and inpainting</td></tr>
<tr><td>Senorita-2M</td><td>3.533</td><td>3.883</td><td>Source object removal and inpainting</td></tr>
<tr><td>InsViE-1M</td><td>3.133</td><td>3.667</td><td>Video inversion and reconstruction guidance</td></tr>
<tr><td>Ditto</td><td><strong>4.417</strong></td><td>4.733</td><td>Depth-guided generation from source video</td></tr>
<tr><td><strong>Ours</strong></td><td>4.375</td><td><strong>4.850</strong></td><td><strong>Optical flow guided mask propagation</strong></td></tr>
</table>


</div>
</section>


  <!-- Object Removal -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Object Removal</h2>

      <div class="videos-list">
      <style>
      .video-block {
        margin-bottom: 2rem; 
      }

      .video-block h3 {
        margin-bottom: 0.1rem; 
      }
      </style>
            
        <div class="video-block">
          <h3 class="title is-5 has-text-centered">Remove the entire wooden boardwalk from the scene.</h3>
          <video poster="" playsinline autoplay muted loop height="90%" 
                 src="static/videos/remove_bridge.mp4"></video>
        </div>

        <div class="video-block">
          <h3 class="title is-5 has-text-centered">Remove the wooden stakes in the front of the horse.</h3>
          <video poster="" playsinline autoplay muted loop height="90%" 
                 src="static/videos/remove_wood.mp4"></video>
        </div>

        <div class="video-block">
          <h3 class="title is-5 has-text-centered">Remove the fishing boat on the left.</h3>
          <video poster="" playsinline autoplay muted loop height="90%" 
                 src="static/videos/remove_boat.mp4"></video>
        </div>


      </div>

    </div>
  </div>
</section>

<!-- Object Addition -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Object Addition</h2>

      <div class="videos-list">
      <style>
      .video-block {
        margin-bottom: 2rem; 
      }

      .video-block h3 {
        margin-bottom: 0.1rem; 
      }
      </style>


        <div class="video-block">
          <h3 class="title is-5 has-text-centered">Add a pair of realistic sunglasses to the man in the video.</h3>
          <video poster="" playsinline autoplay muted loop height="90%" 
                 src="static/videos/add_glass.mp4"></video>
        </div>

        <div class="video-block">
          <h3 class="title is-5 has-text-centered">Add a square red flag on the top of the boat.</h3>
          <video poster="" playsinline autoplay muted loop height="90%" 
                 src="static/videos/add_flag.mp4"></video>
        </div>

        <div class="video-block">
          <h3 class="title is-5 has-text-centered">Put a white helmet on the head of the hockey player.</h3>
          <video poster="" playsinline autoplay muted loop height="90%" 
                 src="static/videos/add_helmet.mp4"></video>
        </div>



      </div>

    </div>
  </div>
</section>


  <!-- Method Overview -->
  <section class="section hero is-small is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full">
          <div class="content">
            <h2 class="title is-3">Method Overview</h2>
            <center>
              <img src="static/images/datapipeline.png"
                   alt="LoVoRA Dataset"
                   class="center-image blend-img-background" />
            </center>
            <div class="level-set has-text-justified" style="margin-top: 1rem;">
              <p>
                Overview of LoVoRA dataset construction pipeline. Starting from high-quality image editing pairs, we synthesize instruction-based video editing data through five: I2V translation, mask generation, optical flow estimation, mask propagation, and video inpainting.
              </p>
            </div>
            <center style="margin-top: 2rem;">
              <img src="static/images/framework.png"
                   alt="LoVoRA Framework"
                   class="center-image blend-img-background" />
            </center>
            <div class="level-set has-text-justified" style="margin-top: 1rem;">
              <p>
                Overview of the proposed LoVoRA framework. The input video is encoded by a spatio-temporal VAE to produce latents. Encoded latents are channel-concatenated with noisy target latents and processed by a DiT backbone to predict the rectified-flow velocity field. A Diffusion Mask Predictor reads selected DiT token features and predicts a spatio-temporal diff mask used during training.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Footer -->
  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the
              <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">
                Academic Project Page Template
              </a>.
              You are free to borrow the structure of this website; we just ask that you link back to this page in the footer.
              <br>
              This website is licensed under a
              <a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank">
                Creative Commons Attribution-ShareAlike 4.0 International License
              </a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>



</body>
</html>
